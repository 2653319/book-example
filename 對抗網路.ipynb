{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPA4sZIFayDDMsJ06sBby/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2653319/book-example/blob/main/%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1W1XFsND5jl"
      },
      "outputs": [],
      "source": [
        "#判別器   使用多層全連接網路建立  對抗網路\n",
        "class discriminator(nn.Module):\n",
        "  def __init__ (self):\n",
        "    super(discriminator, self).__init__()\n",
        "    self.dis = nn.Sequential(\n",
        "        nn.Linear(784,256)\n",
        "        nn.LeakyReLU(0.2),#斜率為0.2 的啟動函數\n",
        "        nn.Linear(256,256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(256,1),\n",
        "        nn.Sigmoid()  #將結果對應到0~1之間機率進行二分法\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.dis(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#生產器\n",
        "class generator(nn.Module):  \n",
        "  def __init__ (self,input_size):\n",
        "    super(generator,self).__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        nn.Linear(input_size,256)\n",
        "        nn.LeakyReLU(True),\n",
        "        nn.Linear(256,256),\n",
        "        nn.LeakyReLU(True),\n",
        "        nn.Linear(256,784),\n",
        "        nn.Tanh()  #使用函數Tanh() 將資料分布到-1~1之間 \n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.gen(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "MVR1pyaCk_2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#定義損失函數和最佳化函數\n",
        "criterion = nn.BCELoss()  #二分類的損失函數\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003) #使用Adam最佳化函式 學習率0.0003\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)"
      ],
      "metadata": {
        "id": "CIxqr79Zl7z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#判別器訓練\n",
        "img = img.view(num_img, -1)\n",
        "real_img = Variable(img).cuda()\n",
        "real_label = Variable(torch.ones(num_img)).cuda() #真實資料  全1\n",
        "fake_label = Variable(torch.zero(num_img)).cuda() #假資料  全0\n",
        "\n",
        "real_out = D(real_img) #將真圖片丟進判別器 取得值real_out\n",
        "d_loss_real = criterion(real_out, real_label)  #將real_out 和 real_label 丟入 計算並取得loss\n",
        "#透過real_out和real_label的差距的loss 得知兩者差距為多少 用於改善\n",
        "real_scores = real_out\n",
        "\n",
        "z = Variable(torch.randn(num_img, z_dimension)).cuda()  #獲得隨機雜訊\n",
        "fake_img = G(z)      #產生假圖片\n",
        "fake_out = D(fake_img)   #經過判別器獲得的結果\n",
        "d_loss_fake = criterion(fake_out, fake_label)  #將fake_out 和 fake_label 丟入 計算並取得 loss  \n",
        "#透過fake_out和fake_label差距的loss 得知兩者差距為多少 用於改善\n",
        "\n",
        "fake_scores = fake_out\n",
        "\n",
        "d_loss = d_loss_real + d_loss_fake  #兩者loss相加 獲得的loss 用反向傳播 更新判斷器\n",
        "d_optimizer.zero_grad()   #歸0梯度\n",
        "d_loss.backward()     #反向傳播\n",
        "d_optimizer.step()    #更新產生網路的參數"
      ],
      "metadata": {
        "id": "9-YrabNvmWk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#產生器訓練\n",
        "z = Variable(torch.randn(num_img, z_dimension)).cuda()    #獲得隨機雜訊\n",
        "fake_img = G(z)   #產生假圖片\n",
        "output = D(fake_img)  #經過判別器獲得的結果\n",
        "g_loss = criterion(output, real_label)  #獲得假圖片與真實圖片的label的loss  得知差距  用於改善\n",
        "\n",
        "g_optimizer.zero_grad()   #歸0梯度\n",
        "g_loss.backward()   #反向傳播\n",
        "g_optimizer.step()   #更新產生網路的參數\n"
      ],
      "metadata": {
        "id": "StXghEKepRVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#使用旋積神經網路建立  對抗網路"
      ],
      "metadata": {
        "id": "MTJTNAZ1rAj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#判斷器\n",
        "class discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(discriminator, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, 5, padding = 2),  #batch, 32,28,28\n",
        "        nn.LeakReLU(0.2,True),\n",
        "        nn.AvgPool2d(2, stride=2)  #batch, 32,14,14\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 64, 5, padding = 2), #batch, 64,14,14\n",
        "        nn.LeakReLU(0.2,True),\n",
        "        nn.AvgPool2d(2, stride=2)   #batch, 64,7,7\n",
        "    )\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(64*7*7, 1024),  \n",
        "        nn.LeakyReLU(0.2, True),\n",
        "        nn.Linear(1024, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    x: batch, width, height, channel=1\n",
        "    '''\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = x.view(x.size(0),-1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "#產生器\n",
        "class generator(nn.Module):\n",
        "  def __init__ (self, input_size, num_feature):\n",
        "    super(genertaor, self).__init__()\n",
        "    self.fc = nn.Linear(input_size, num_feature) #batch, 3136 = 1 x 56 x 56\n",
        "    self.br = nn.Sequential(\n",
        "        nn.BatchNorm2d(1),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "    self.downsampe1 = nn.Sequential(\n",
        "        nn.Conv2d(1, 50, 3, stride=1, padding=1),  #batch, 50,56,56\n",
        "        nn.BatchNorm2d(50),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "    self.downsampe2 = nn.Sequential(\n",
        "        nn.Conv2d(50, 25, 3, stride=1, padding=1), #batch, 25,56,56\n",
        "        nn.BatchNorm2d(25),\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "    self.downsampe3 = nn.Sequential(\n",
        "        nn.Conv2d(25, 1, 2, stride=2),  #batch, 1,28,28\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.fc(x)\n",
        "    x = x.view(x.size(0), 1, 56, 56)\n",
        "    x = self.br(x)\n",
        "    x = self.downsampe1(x)\n",
        "    x = self.downsampe2(x)\n",
        "    x = self.downsampe3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "x2ExEoamq83M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#判別器訓練\n",
        "img = img.view(num_img, -1)\n",
        "real_img = Variable(img).cuda()\n",
        "real_label = Variable(torch.ones(num_img)).cuda() #真實資料  全1\n",
        "fake_label = Variable(torch.zero(num_img)).cuda() #假資料  全0\n",
        "\n",
        "real_out = D(real_img) #將真圖片丟進判別器 取得值real_out\n",
        "d_loss_real = criterion(real_out, real_label)  #將real_out 和 real_label 丟入 計算並取得loss\n",
        "#透過real_out和real_label的差距的loss 得知兩者差距為多少 用於改善\n",
        "real_scores = real_out\n",
        "\n",
        "z = Variable(torch.randn(num_img, z_dimension)).cuda()  #獲得隨機雜訊\n",
        "fake_img = G(z)      #產生假圖片\n",
        "fake_out = D(fake_img)   #經過判別器獲得的結果\n",
        "d_loss_fake = criterion(fake_out, fake_label)  #將fake_out 和 fake_label 丟入 計算並取得 loss  \n",
        "#透過fake_out和fake_label差距的loss 得知兩者差距為多少 用於改善\n",
        "\n",
        "fake_scores = fake_out\n",
        "\n",
        "d_loss = d_loss_real + d_loss_fake  #兩者loss相加\n",
        "d_optimizer.zero_grad()   #歸0梯度\n",
        "d_loss.backward()     #反向傳播\n",
        "d_optimizer.step()    #更新產生網路的參數"
      ],
      "metadata": {
        "id": "0l8_hoTm7rMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#產生器訓練\n",
        "z = Variable(torch.randn(num_img, z_dimension)).cuda()    #獲得隨機雜訊\n",
        "fake_img = G(z)   #產生假圖片\n",
        "output = D(fake_img)  #經過判別器獲得的結果\n",
        "g_loss = criterion(output, real_label)  #獲得假圖片與真實圖片的label的loss  得知差距  用於改善\n",
        "\n",
        "g_optimizer.zero_grad()   #歸0梯度\n",
        "g_loss.backward()   #反向傳播\n",
        "g_optimizer.step()   #更新產生網路的參數"
      ],
      "metadata": {
        "id": "bcl9kAQS7rve"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2653319/book-example/blob/main/%E5%BE%9E%E6%84%9B%E7%88%BE%E8%98%AD%E6%AD%8C%E8%A9%9E%E7%94%9F%E6%88%90%E6%96%87%E6%9C%AC_ALL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb1y-RAUWGZ8"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C3/W4/ungraded_labs/C3_W4_Lab_2_irish_lyrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqIxQYm8h06Z"
      },
      "source": [
        "# Ungraded Lab：從愛爾蘭歌詞生成文本\n",
        "\n",
        "在之前的實驗室中，您只用一首歌曲訓練了一個模型。您可能已經發現輸出文本很快就會變得亂碼或重複。即使您調整了超參數，該模型仍然會受到其僅 263 個單詞的詞彙量的限制。如果您在更大的語料庫上訓練該模型，它將更加靈活，這就是您將在本實驗室中所做的事情。您將使用更多愛爾蘭歌曲的歌詞，然後查看生成的文本的樣子。您還將看到這如何影響從數據準備到模型訓練的過程。讓我們開始吧！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb1mfOvch4Sv"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmBFI788pOXx"
      },
      "source": [
        "## 構建單詞詞彙表\n",
        "\n",
        "您將首先下載歌詞數據集。這些將來自傳統愛爾蘭歌曲的彙編，您可以在 [這裡](https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C3/W4/misc/Laurences_generated_poetry) 看到它們。文本文件）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pylt5qZYsWPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af83e36-e68f-4dd0-fe66-f77450e1a071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-10 08:36:47--  https://storage.googleapis.com/tensorflow-1-public/course3/irish-lyrics-eof.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 142.250.99.128, 173.194.202.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68970 (67K) [text/plain]\n",
            "Saving to: ‘irish-lyrics-eof.txt’\n",
            "\n",
            "\rirish-lyrics-eof.tx   0%[                    ]       0  --.-KB/s               \rirish-lyrics-eof.tx 100%[===================>]  67.35K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-05-10 08:36:48 (86.1 MB/s) - ‘irish-lyrics-eof.txt’ saved [68970/68970]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course3/irish-lyrics-eof.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v6JYQGNPXCW"
      },
      "source": [
        "\n",
        "接下來，您將小寫並將純文本拆分為句子列表："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKOO7DFCPX3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f19d0c4-767e-454e-e445-2d136a01d9dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['你好，今天過的好嗎?', '學習自然語言']\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = open('./irish-lyrics-eof.txt').read()\n",
        "\n",
        "# Lowercase and split the text\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "corpus = ['你好，今天過的好嗎?','學習自然語言']\n",
        "# Preview the result\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkP2CP0qP8RD"
      },
      "source": [
        "\n",
        "從這裡，您可以初始化 `Tokenizer` 類並生成單詞索引字典："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cf9ce9-bedb-407d-ad65-9bc33564c209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word index dictionary: {'你好，今天過的好嗎': 1, '學習自然語言': 2}\n",
            "total words: 3\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Generate the word index dictionary\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# 定義總字數。您為索引“0”添加 1，這只是填充標記。\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(f'word index dictionary: {tokenizer.word_index}')\n",
        "print(f'total words: {total_words}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK29FzZ7QW-4"
      },
      "source": [
        "## 預處理數據集\n",
        "\n",
        "接下來，您將為模型生成輸入和標籤。該過程將與之前的實驗室相同。 `xs` 或模型的輸入將是填充序列，而 `ys` 或標籤是 one-hot 編碼數組。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soPGVheskaQP"
      },
      "outputs": [],
      "source": [
        "# 初始化序列列表\n",
        "input_sequences = []\n",
        "\n",
        "# 循環遍歷每一行\n",
        "for line in corpus:\n",
        "\n",
        "\t# 標記當前行\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "\t# 循環多次以生成子短語\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\t\n",
        "\t\t# 生成副詞\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\n",
        "\t\t# 將副短語附加到序列列表\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# 獲取最長線的長度\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# 填充所有序列\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# 通過拆分子短語中的最後一個標記來創建輸入和標籤\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "# 將標籤轉換為 one-hot 數組\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmWHCO0dQGlZ"
      },
      "source": [
        "然後，您可以打印一些示例作為完整性檢查。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJtwVB2NbOAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ea36b4-323e-4560-ebd0-bbc66dbb1788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample sentence: ['come', 'all', 'ye', 'maidens', 'young', 'and', 'fair']\n",
            "[51, 12, 96, 1217, 48, 2, 69]\n"
          ]
        }
      ],
      "source": [
        "# Get sample sentence\n",
        "sentence = corpus[0].split()\n",
        "print(f'sample sentence: {sentence}')\n",
        "\n",
        "# Initialize token list\n",
        "token_list = []\n",
        "\n",
        "# Look up the indices of each word and append to the list\n",
        "for word in sentence: \n",
        "  token_list.append(tokenizer.word_index[word])\n",
        "\n",
        "# Print the token list\n",
        "print(token_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMr6kKfzROlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7389f5-aec0-4d07-d163-f40d188aa50e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token list: [   0    0    0    0    0    0    0    0    0   51   12   96 1217   48\n",
            "    2]\n",
            "decoded to text: ['come all ye maidens young and']\n",
            "one-hot label: [0. 0. 0. ... 0. 0. 0.]\n",
            "index of label: 69\n"
          ]
        }
      ],
      "source": [
        "# Pick element\n",
        "elem_number = 5\n",
        "\n",
        "# Print token list and phrase\n",
        "print(f'token list: {xs[elem_number]}')\n",
        "print(f'decoded to text: {tokenizer.sequences_to_texts([xs[elem_number]])}')\n",
        "\n",
        "# Print label\n",
        "print(f'one-hot label: {ys[elem_number]}')\n",
        "print(f'index of label: {np.argmax(ys[elem_number])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49Cv68JOakwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e31dba-66c1-45a1-e87e-4744bf2aafb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token list: [   0    0    0    0    0    0    0    0    0    0   51   12   96 1217\n",
            "   48]\n",
            "decoded to text: ['come all ye maidens young']\n",
            "one-hot label: [0. 0. 1. ... 0. 0. 0.]\n",
            "index of label: 2\n"
          ]
        }
      ],
      "source": [
        "# Pick element\n",
        "elem_number = 4\n",
        "\n",
        "# Print token list and phrase\n",
        "print(f'token list: {xs[elem_number]}')\n",
        "print(f'decoded to text: {tokenizer.sequences_to_texts([xs[elem_number]])}')\n",
        "\n",
        "# Print label\n",
        "print(f'one-hot label: {ys[elem_number]}')\n",
        "print(f'index of label: {np.argmax(ys[elem_number])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKWWUZm5VPG9"
      },
      "source": [
        "## 構建和編譯模型\n",
        "\n",
        "接下來，您將構建和編譯模型。我們將一些超參數放在代碼單元的頂部，以便您以後可以根據需要輕鬆調整它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d658ac66-0bcc-4b41-fb1c-a86ef4772163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 15, 100)           269000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 300)              301200    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2690)              809690    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,379,890\n",
            "Trainable params: 1,379,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 100\n",
        "lstm_units = 150\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "          Embedding(total_words, embedding_dim, input_length=max_sequence_len-1),\n",
        "          Bidirectional(LSTM(lstm_units)),\n",
        "          Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "# 使用分類交叉熵，因為這是一個多類問題\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV4z8MCuX8Ad",
        "outputId": "c9071269-eeaa-4410-b61d-8c5bd18e5b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12038, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPXoAt6dX9TB",
        "outputId": "44d68e80-c6e8-41b3-db5f-2ca70c52bd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12038, 2690)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpI0d9cfR43c"
      },
      "source": [
        "## 訓練模型\n",
        "\n",
        "從上面的模型摘要中，您會注意到可訓練參數的數量比之前實驗室中的要大得多。因此，這通常意味著更慢的訓練時間。在 Colab 中啟用 GPU 的情況下，每個 epoch 大約需要 7 秒，並且在 100 個 epoch 後您將達到大約 76% 的準確度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc4zC7C4jJpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2db3ce-7967-48ae-8ec2-a5760fec660d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "377/377 [==============================] - 16s 19ms/step - loss: 6.6670 - accuracy: 0.0724\n",
            "Epoch 2/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 5.7769 - accuracy: 0.1137\n",
            "Epoch 3/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 4.9108 - accuracy: 0.1668\n",
            "Epoch 4/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 4.0179 - accuracy: 0.2330\n",
            "Epoch 5/100\n",
            "377/377 [==============================] - 7s 20ms/step - loss: 3.2028 - accuracy: 0.3285\n",
            "Epoch 6/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 2.5793 - accuracy: 0.4248\n",
            "Epoch 7/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 2.1250 - accuracy: 0.5039\n",
            "Epoch 8/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.7503 - accuracy: 0.5850\n",
            "Epoch 9/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.4814 - accuracy: 0.6375\n",
            "Epoch 10/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.3663 - accuracy: 0.6678\n",
            "Epoch 11/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.1726 - accuracy: 0.7118\n",
            "Epoch 12/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.0535 - accuracy: 0.7421\n",
            "Epoch 13/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9930 - accuracy: 0.7564\n",
            "Epoch 14/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.0409 - accuracy: 0.7395\n",
            "Epoch 15/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.1237 - accuracy: 0.7117\n",
            "Epoch 16/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.2399 - accuracy: 0.6842\n",
            "Epoch 17/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.3498 - accuracy: 0.6575\n",
            "Epoch 18/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.1450 - accuracy: 0.7053\n",
            "Epoch 19/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.0029 - accuracy: 0.7395\n",
            "Epoch 20/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8959 - accuracy: 0.7682\n",
            "Epoch 21/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.8274 - accuracy: 0.7874\n",
            "Epoch 22/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.7955 - accuracy: 0.7978\n",
            "Epoch 23/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8230 - accuracy: 0.7876\n",
            "Epoch 24/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9998 - accuracy: 0.7422\n",
            "Epoch 25/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.3439 - accuracy: 0.6603\n",
            "Epoch 26/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.3581 - accuracy: 0.6573\n",
            "Epoch 27/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.1669 - accuracy: 0.6982\n",
            "Epoch 28/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0420 - accuracy: 0.7274\n",
            "Epoch 29/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9256 - accuracy: 0.7578\n",
            "Epoch 30/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8958 - accuracy: 0.7729\n",
            "Epoch 31/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8636 - accuracy: 0.7781\n",
            "Epoch 32/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9326 - accuracy: 0.7636\n",
            "Epoch 33/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0311 - accuracy: 0.7301\n",
            "Epoch 34/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.1834 - accuracy: 0.6971\n",
            "Epoch 35/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.1359 - accuracy: 0.7065\n",
            "Epoch 36/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0346 - accuracy: 0.7329\n",
            "Epoch 37/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9631 - accuracy: 0.7505\n",
            "Epoch 38/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9398 - accuracy: 0.7546\n",
            "Epoch 39/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8994 - accuracy: 0.7650\n",
            "Epoch 40/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8998 - accuracy: 0.7662\n",
            "Epoch 41/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.8932 - accuracy: 0.7675\n",
            "Epoch 42/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9199 - accuracy: 0.7610\n",
            "Epoch 43/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9397 - accuracy: 0.7569\n",
            "Epoch 44/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9645 - accuracy: 0.7475\n",
            "Epoch 45/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0152 - accuracy: 0.7349\n",
            "Epoch 46/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.0912 - accuracy: 0.7206\n",
            "Epoch 47/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0017 - accuracy: 0.7392\n",
            "Epoch 48/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9745 - accuracy: 0.7443\n",
            "Epoch 49/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0266 - accuracy: 0.7387\n",
            "Epoch 50/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9515 - accuracy: 0.7521\n",
            "Epoch 51/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9494 - accuracy: 0.7517\n",
            "Epoch 52/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9325 - accuracy: 0.7575\n",
            "Epoch 53/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9163 - accuracy: 0.7662\n",
            "Epoch 54/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9445 - accuracy: 0.7607\n",
            "Epoch 55/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9199 - accuracy: 0.7617\n",
            "Epoch 56/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9187 - accuracy: 0.7679\n",
            "Epoch 57/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.8946 - accuracy: 0.7675\n",
            "Epoch 58/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9475 - accuracy: 0.7549\n",
            "Epoch 59/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9411 - accuracy: 0.7561\n",
            "Epoch 60/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9311 - accuracy: 0.7569\n",
            "Epoch 61/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.8848 - accuracy: 0.7679\n",
            "Epoch 62/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8770 - accuracy: 0.7770\n",
            "Epoch 63/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9864 - accuracy: 0.7526\n",
            "Epoch 64/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0117 - accuracy: 0.7414\n",
            "Epoch 65/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 1.0336 - accuracy: 0.7353\n",
            "Epoch 66/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0426 - accuracy: 0.7363\n",
            "Epoch 67/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9798 - accuracy: 0.7514\n",
            "Epoch 68/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9447 - accuracy: 0.7573\n",
            "Epoch 69/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9095 - accuracy: 0.7707\n",
            "Epoch 70/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9018 - accuracy: 0.7705\n",
            "Epoch 71/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9132 - accuracy: 0.7700\n",
            "Epoch 72/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9183 - accuracy: 0.7672\n",
            "Epoch 73/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9403 - accuracy: 0.7600\n",
            "Epoch 74/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9985 - accuracy: 0.7436\n",
            "Epoch 75/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9565 - accuracy: 0.7574\n",
            "Epoch 76/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 1.0103 - accuracy: 0.7499\n",
            "Epoch 77/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9743 - accuracy: 0.7529\n",
            "Epoch 78/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9701 - accuracy: 0.7534\n",
            "Epoch 79/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9748 - accuracy: 0.7536\n",
            "Epoch 80/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9567 - accuracy: 0.7549\n",
            "Epoch 81/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9609 - accuracy: 0.7588\n",
            "Epoch 82/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9179 - accuracy: 0.7666\n",
            "Epoch 83/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8944 - accuracy: 0.7679\n",
            "Epoch 84/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9535 - accuracy: 0.7611\n",
            "Epoch 85/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9914 - accuracy: 0.7495\n",
            "Epoch 86/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9771 - accuracy: 0.7484\n",
            "Epoch 87/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9806 - accuracy: 0.7514\n",
            "Epoch 88/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9851 - accuracy: 0.7535\n",
            "Epoch 89/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9666 - accuracy: 0.7543\n",
            "Epoch 90/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9447 - accuracy: 0.7564\n",
            "Epoch 91/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9474 - accuracy: 0.7659\n",
            "Epoch 92/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9360 - accuracy: 0.7623\n",
            "Epoch 93/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.9644 - accuracy: 0.7574\n",
            "Epoch 94/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9567 - accuracy: 0.7557\n",
            "Epoch 95/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8883 - accuracy: 0.7747\n",
            "Epoch 96/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.8813 - accuracy: 0.7778\n",
            "Epoch 97/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8925 - accuracy: 0.7755\n",
            "Epoch 98/100\n",
            "377/377 [==============================] - 7s 18ms/step - loss: 0.8913 - accuracy: 0.7701\n",
            "Epoch 99/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.8897 - accuracy: 0.7727\n",
            "Epoch 100/100\n",
            "377/377 [==============================] - 7s 19ms/step - loss: 0.9334 - accuracy: 0.7640\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(xs, ys, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgAzLnLATFts"
      },
      "source": [
        "您可以在下面可視化準確度，以了解它如何隨著訓練的進行而波動。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YXGelKThoTT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "901afeab-6ebf-4dff-bfeb-dd33d287d3d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot utility\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the accuracy\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gxKIcvGTUnw"
      },
      "source": [
        "\n",
        "## 生成文本\n",
        "\n",
        "現在您可以讓模型製作自己的歌曲或詩歌！因為它是在更大的語料庫上訓練的，所以下面的結果應該像以前一樣包含更少的重複。下面的代碼根據最高概率輸出選擇下一個單詞。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7522fb9a-ab5e-4fa5-a6f6-5d1951fd36a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "help me obi-wan kinobi youre my only hope sitting in fray merry divinity much again in tory women and how his pike flashed in your waters so mild a stone youd beguile bare my life away thee might see it goes on gone by in strife steps i leaps i and receiver i wish i could meet me i love a love and i sat i wish you is a delight in sorrow and gone far away from slight a whirligig mary honey shaken i was stole and thinking of athy one jeremy lanigan hill is barney more and late i right any tay black and gathered them\n"
          ]
        }
      ],
      "source": [
        "# Define seed text\n",
        "seed_text = \"help me obi-wan kinobi youre my only hope\"\n",
        "\n",
        "# Define total words to predict\n",
        "next_words = 100\n",
        "\n",
        "# Loop until desired length is reached\n",
        "for _ in range(next_words):\n",
        "\n",
        "\t# Convert the seed text to a token sequence\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "\t# Pad the sequence\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\n",
        "\t# Feed to the model and get the probabilities for each index\n",
        "\tprobabilities = model.predict(token_list)\n",
        "\n",
        "\t# Get the index with the highest probability\n",
        "\tpredicted = np.argmax(probabilities, axis=-1)[0]\n",
        "\n",
        "\t# Ignore if index is 0 because that is just the padding.\n",
        "\tif predicted != 0:\n",
        "\t\t\n",
        "\t\t# Look up the word associated with the index. \n",
        "\t\toutput_word = tokenizer.index_word[predicted]\n",
        "\n",
        "\t\t# Combine with the seed text\n",
        "\t\tseed_text += \" \" + output_word\n",
        "\n",
        "# Print the result\t\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHtrtAFAT6tn"
      },
      "source": [
        "\n",
        "這裡又是獲取前 3 個預測並隨機選擇一個的代碼."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJfzKm-8mVKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6d47fe-039c-4e1b-b695-d3e2bec037a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "help me obi-wan kinobi youre my only hope sitting in fray erin wid here that dying saw the left old and down side this half dozen to mine dawn drawn till it is creole sons is fresh we were spreading hill ill dew and me to on their dresses all flashed rattling for a foemans ball beside my mothers i ringlets there i made there will times them by down two three long green when i meet a colleen sweet boneless high nice the valley they didnt take me fists and me still fall god on my bride is losing i could gone in ballygrant right house and\n"
          ]
        }
      ],
      "source": [
        "# Define seed text\n",
        "seed_text = \"help me obi-wan kinobi youre my only hope\"\n",
        "\n",
        "# Define total words to predict\n",
        "next_words = 100\n",
        "\n",
        "# Loop until desired length is reached\n",
        "for _ in range(next_words):\n",
        "\n",
        "\t# Convert the seed text to a token sequence\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "\t# Pad the sequence\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\n",
        "\t# Feed to the model and get the probabilities for each index\n",
        "  probabilities = model.predict(token_list)\n",
        "\n",
        "  # Pick a random number from [1,2,3]\n",
        "  choice = np.random.choice([1,2,3])\n",
        "\t\n",
        "  # Sort the probabilities in ascending order \n",
        "  # and get the random choice from the end of the array\n",
        "  predicted = np.argsort(probabilities)[0][-choice]\n",
        "\n",
        "\t# Ignore if index is 0 because that is just the padding.\n",
        "  if predicted != 0:\n",
        "\t\t\n",
        "\t\t# Look up the word associated with the index. \n",
        "\t  output_word = tokenizer.index_word[predicted]\n",
        "\n",
        "\t\t# Combine with the seed text\n",
        "\t  seed_text += \" \" + output_word\n",
        "\n",
        "# Print the result\t\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP0--sdMUJ_k"
      },
      "source": [
        "##包起來\n",
        "\n",
        "本實驗展示了使用更大的數據集來訓練文本生成模型的效果。正如預期的那樣，這將需要更長的時間來準備和訓練，但輸出不太可能變得重複或亂碼。嘗試調整超參數，看看是否能得到更好的結果。您還可以在此處找到一些其他文本數據集並使用它來訓練模型。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
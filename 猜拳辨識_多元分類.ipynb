{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2653319/book-example/blob/main/%E7%8C%9C%E6%8B%B3%E8%BE%A8%E8%AD%98_%E5%A4%9A%E5%85%83%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi6QEZ_nD7HH"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W4/ungraded_lab/C2_W4_Lab_1_multi_class_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UD-1_xY-h2u"
      },
      "source": [
        "未分級實驗室：多級分類器\n",
        "在本實驗中，您將了解如何構建模型來區分兩個以上的類。該代碼將與您之前使用的代碼相似，只是對模型和訓練參數進行了一些關鍵更改。讓我們潛入吧！"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##需更改的函式\n",
        "\n",
        "此猜拳為多元，以往都是二元\n",
        "\n",
        "1.模型的輸出，激活函式需更改，由sigmoid(二元) -> softmax(多元)\n",
        "\n",
        "2.圖片生產器得class_mod需更改，由binary(二元) -> categorical(多元)\n",
        "\n",
        "3.模型的loss需更改，由binary_crossentropy(二元) -> categorical_crossentropy(多元) \n",
        "\n"
      ],
      "metadata": {
        "id": "R9HX3MV3FQfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v5fRjvMGGlFv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvwVR5lHA8q_"
      },
      "source": [
        "## 下載並準備數據集\n",
        "\n",
        "您將使用 [Rock-Paper-Scissors 數據集](http://www.laurencemoroney.com/rock-paper-scissors-dataset/)，這是一個包含石頭、紙和剪刀姿勢的手圖像庫。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1psgpSWD7HM"
      },
      "outputs": [],
      "source": [
        "# Download the train set\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week4/rps.zip\n",
        "    \n",
        "# Download the test set\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week4/rps-test-set.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnYP_HhYNVUK"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Extract the archive\n",
        "local_zip = './rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/rps-train')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = './rps-test-set.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/rps-test')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3vqjYrpB0hI"
      },
      "source": [
        "像往常一樣，您會將目錄名稱分配給變量，並將文件名作為健全性檢查。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrxdR83ANgjS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "base_dir = 'tmp/rps-train/rps'\n",
        "\n",
        "rock_dir = os.path.join(base_dir, 'rock')\n",
        "paper_dir = os.path.join(base_dir, 'paper')\n",
        "scissors_dir = os.path.join(base_dir, 'scissors')\n",
        "\n",
        "print('total training rock images:', len(os.listdir(rock_dir)))\n",
        "print('total training paper images:', len(os.listdir(paper_dir)))\n",
        "print('total training scissors images:', len(os.listdir(scissors_dir)))\n",
        "\n",
        "rock_files = os.listdir(rock_dir)\n",
        "print(rock_files[:10])\n",
        "\n",
        "paper_files = os.listdir(paper_dir)\n",
        "print(paper_files[:10])\n",
        "\n",
        "scissors_files = os.listdir(scissors_dir)\n",
        "print(scissors_files[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_CNSs6B-8y"
      },
      "source": [
        "您還可以檢查一些圖像以查看模型輸入的多樣性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp9dLel9N9DS"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "pic_index = 2\n",
        "\n",
        "next_rock = [os.path.join(rock_dir, fname) \n",
        "                for fname in rock_files[pic_index-2:pic_index]]\n",
        "next_paper = [os.path.join(paper_dir, fname) \n",
        "                for fname in paper_files[pic_index-2:pic_index]]\n",
        "next_scissors = [os.path.join(scissors_dir, fname) \n",
        "                for fname in scissors_files[pic_index-2:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_rock+next_paper+next_scissors):\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('Off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufa0YF5oCpYw"
      },
      "source": [
        "##建立模型\n",
        "\n",
        "然後，您將構建您的 CNN。您將使用 4 個卷積層和 64-64-128-128 過濾器，然後附加一個“Dropout”層以避免過度擬合，並添加一些 Dense 層用於分類。輸出層將是由 [Softmax] (https://www.tensorflow.org/api_docs/python/tf/nn/softmax) 激活的 3 神經元密集層。當您在 Fashion MNIST 進行培訓時，您已經在課程 1 中看到了這一點。它將你的輸出縮放為一組加起來為 1 的概率。這個 3 神經元輸出的順序將是 `paper`-`rock`-`scissors`（例如，`[0.8 0.2 0.0]` 輸出表示模型預測紙張的概率為 80%，岩石的概率為 20%。\n",
        "\n",
        "You can examine the architecture with `model.summary()` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgvGg2nsCj-0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  \n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P1iuHGiFrPV"
      },
      "source": [
        "然後，您將編譯模型。這裡的關鍵變化是 `loss` 函數。而在您將 `binary_crossentropy` 用於 2 個類之前，您將其更改為 [categorical_crossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-function) 以將其擴展到更多類。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OskuZ2ThFqmg"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ps7kIRaFRIC"
      },
      "source": [
        "準備 ImageDataGenerator\n",
        "您將像以前一樣準備生成器。您將為數據增強設置訓練集，以便它可以模仿模型需要學習的其他姿勢。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWTisYLQM1aM"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"tmp/rps-train/rps\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "VALIDATION_DIR = \"tmp/rps-test/rps-test-set\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orf1QQlGGyOe"
      },
      "source": [
        "訓練模型並評估結果\n",
        "您將訓練 25 個 epoch，然後評估結果。觀察訓練和驗證的準確性如何呈上升趨勢。這很好地表明該模型僅對您的訓練集沒有過度擬合。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mHX5L7HFXQ7"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeTRVCr6aosw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3ps8Q1tpYMG"
      },
      "source": [
        "#  模型預測\n",
        "\n",
        "您應該能夠在此處上傳圖像並對其進行分類而不會崩潰。但是，此代碼塊僅適用於 Google Colab。您可以使用自己的圖像或使用可用的圖像 [此處](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-validation.zip)\n",
        "\n",
        "**Important Note:** Due to some compatibility issues, the following code block will result in an error after you select the images(s) to upload if you are running this notebook as a `Colab` on the `Safari` browser. For all other browsers, continue with the next code block and ignore the next one after it.\n",
        "\n",
        "_For Safari users: please comment out or skip the code block below, uncomment the next code block and run it._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZABJp7T3VLCU"
      },
      "outputs": [],
      "source": [
        "## CODE BLOCK FOR NON-SAFARI BROWSERS\n",
        "## SAFARI USERS: PLEASE SKIP THIS BLOCK AND RUN THE NEXT ONE INSTEAD\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(fn)\n",
        "  print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rsy_ebEDQsc"
      },
      "source": [
        "`Safari` users will need to upload the images(s) manually in their workspace. Please follow the instructions, uncomment the code block below and run it.\n",
        "\n",
        "Instructions on how to upload image(s) manually in a Colab:\n",
        "\n",
        "1. Select the `folder` icon on the left `menu bar`.\n",
        "2. Click on the `folder with an arrow pointing upwards` named `..`\n",
        "3. Click on the `folder` named `tmp`.\n",
        "4. Inside of the `tmp` folder, `create a new folder` called `images`. You'll see the `New folder` option by clicking the `3 vertical dots` menu button next to the `tmp` folder.\n",
        "5. Inside of the new `images` folder, upload an image(s) of your choice. Drag and drop the images(s) on top of the `images` folder.\n",
        "6. Uncomment and run the code block below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBt6ae3YDQsc"
      },
      "outputs": [],
      "source": [
        "# # CODE BLOCK FOR SAFARI USERS\n",
        "\n",
        "# import os\n",
        "# import numpy as np\n",
        "# from keras.preprocessing import image\n",
        "\n",
        "# images = os.listdir(\"/tmp/images\")\n",
        "\n",
        "# print(images)\n",
        "\n",
        "# for i in images:\n",
        "#     print()\n",
        "#     # predicting images\n",
        "#     path = '/tmp/images/' + i\n",
        "#     img = image.load_img(path, target_size=(150, 150))\n",
        "#     x = image.img_to_array(img)\n",
        "#     x = np.expand_dims(x, axis=0)\n",
        "    \n",
        "#     images = np.vstack([x])\n",
        "#     classes = model.predict(images, batch_size=10)\n",
        "#     print(path)\n",
        "#     print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHRufhQYJJLU"
      },
      "source": [
        "##包起來\n",
        "\n",
        "關於多類分類器的這個簡短練習到此結束。您已經看到，只需進行一些更改，您就能夠轉換您的二元分類器來預測更多類。您在數據和模型準備中使用了相同的技術，並且能夠在 25 個 epoch 中獲得相對較好的結果。為了練習，您可以搜索其他數據集（例如 [here](https://archive.ics.uci.edu/ml/datasets.php) 具有更多類並修改模型以適應它。嘗試嘗試不同的層和數據增強技術來改善您的指標。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}